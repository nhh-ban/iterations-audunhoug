View(mcdonalds.number)
mcdonalds.number <- as.integer(mcdonalds.number)
raw.data %>%
mutate(Docs = row_number()) %>%
filter(cik == "0000063908") %>%
select(Docs)-> mcdonalds.number
mcdonalds.number <- as.numeric(mcdonalds.number)
raw.data %>%
mutate(Docs = row_number()) %>%
filter(cik == "0000077476") %>%
select(Docs)-> pepsi.number
pepsi.number <- as.numeric(pepsi.number)
section.1.business.numbered <- as.data.frame(section.1.business) %>%
mutate(Docs = row_number())
raw.data %>%
mutate(Docs = row_number()) %>%
filter(cik == "0000063908") %>%
select(Docs)-> mcdonalds.number
View(mcdonalds.number)
mcdonalds.doc <- inner_join(x = section.1.business.numbered,
y = mcdonalds.number,
by = "Docs")
raw.data %>%
mutate(Docs = row_number()) %>%
filter(cik == "0000077476") %>%
select(Docs)-> pepsi.number
mcdonalds.doc %>%
select(section.1.business) -> mcdonalds.doc
pepsi.doc <- inner_join(x = section.1.business.numbered,
y = pepsi.number,
by = "Docs")
pepsi.doc %>%
select(section.1.business) -> pepsi.doc
mcdonalds.doc %>%
VectorSource() %>%
Corpus() %>%
DocumentTermMatrix(control = list(removePunctuation = T,
stopwords = T,
removeNumbers = T)) -> dtm.mcdonalds
pepsi.doc %>%
VectorSource() %>%
Corpus() %>%
DocumentTermMatrix(control = list(removePunctuation = T,
stopwords = T,
removeNumbers = T)) -> dtm.pepsi
install.packages("proxy")
library(proxy)
library(proxy)
cosinesim <- simil(x = dtm.mcdonalds, y = dtm.pepsi)
install.packages("text2vec")
library(text2vec)
library(Matrix)
sparse_dtm.mcd <- as(dtm.mcdonalds, "CsparseMatrix")
install.packages("text2vec")
library(text2vec)
install.packages("text2vec")
library(text2vec)
library(Matrix)
sparse_dtm.mcd <- as(dtm.mcdonalds, "CsparseMatrix")
mcdonalds.termFreq <- tibble(term = colnames(dtm.mcdonalds),
freq = col_sums(dtm.mcdonalds))
View(mcdonalds.termFreq)
pepsi.termFreq <- tibble(term = colnames(dtm.pepsi),
freq = col_sums(dtm.pepsi))
library(dplyr)
mcdonalds.termFreq %>%
arrange(-freq) %>%
slice_max(n = 500, order_by = freq) -> mcdonalds.termFreq
mcdonalds.termFreq %>%
arrange(-freq) %>%
slice_max(n = 500) -> mcdonalds.termFreq
mcdonalds.termFreq %>%
slice_max(n = 500, order_by = freq) -> mcdonalds.termFreq
View(mcdonalds.termFreq)
mcdonalds.termFreq %>%
slice_max(n = 500, order_by = freq) -> mcdonalds.termFreq
mcdonalds.termFreq %>%
arrange(desc(freq)) %>%  # Arrange in descending order of frequency
slice_head(n = 500) -> mcdonalds.termFreq
pepsi.termFreq %>%
arrange(desc(freq)) %>%
slice_head(n = 500) -> pepsi.termFreq
joint.df <- full_join(x = mcdonalds.termFreq, y =pepsi.termFreq)
cossim <- simil(joint.df, method = "cosine")
cossim <- simil(x = mcdonalds.termFreq, y = pepsi.termFreq, method = "cosine")
cossim <- cosine(dtm.mcdonalds, dtm.pepsi)
install.packages("lsa")
library(lsa)
cossim <- cosine(dtm.mcdonalds, dtm.pepsi)
cossim <- cosine(mcdonalds.termFreq, pepsi.termFreq)
raw.data %>%
mutate(Docs = row_number()) %>%
filter(cik == "0000063908","0000077476") %>%
select(Docs)-> joint.numbers
raw.data %>%
mutate(Docs = row_number()) %>%
filter(cik %in% c("0000063908","0000077476")) %>%
select(Docs)-> joint.numbers
joint.doc <- inner_join(x = section.1.business.numbered,
y = joint.numbers,
by = "Docs")
setwd("/Users/audunhoug/desktop/BAN432/Lectures/Lecture 12")
# data
load(file = "firm_dataset.Rdata")
# packages
require(tibble)
require(dplyr)
require(tm)
require(slam)
raw.data %>%
mutate(Docs = row_number()) %>%
filter(cik %in% c("0000063908","0000077476")) %>%
select(Docs)-> joint.numbers
# numbering the business section
section.1.business.numbered <- as.data.frame(section.1.business) %>%
mutate(Docs = row_number())
joint.doc <- inner_join(x = section.1.business.numbered,
y = joint.numbers,
by = "Docs")
joint.doc %>%
select(section.1.business) -> joint.doc
joint.doc %>%
VectorSource() %>%
Corpus() %>%
DocumentTermMatrix(control = list(removePunctuation = T,
stopwords = T,
removeNumbers = T)) -> dtm.joint
joint.termFreq <- tibble(term = colnames(dtm.joint),
freq = col_sums(dtm.joint))
View(joint.termFreq)
View(dtm.joint)
View(dtm.joint)
View(joint.doc)
head(dtm.joint)
summary(dtm.joint)
View(joint.doc)
matrix1 <- as.matrix(dtm.joint)
View(joint.doc)
require(tm)
require(tm)
require(slam)
require(tidyverse)
setwd("/Users/audunhoug/desktop/BAN432/Lectures/Lecture 12")
load(file = "firm_dataset.Rdata")
A <- c(1,0,0)
B <- c(0,1,1)
CosineSimilarity <- function(A,B){
sum(A*B) / sqrt( sum(A^2) * sum(B^2))
}
CosineSimilarity(A,B)
CosineSimilarity(A,B)
CosineSimilarity(A,B)
CosineSimilarity <- function(A,B){
sum(A*B) / (sqrt( sum(A^2) * sum(B^2)))
}
CosineSimilarity(A,B)
B <- c(1,0,0)
CosineSimilarity(A,B)
B <- c(1,1,0)
CosineSimilarity(A,B)
dtm <- DocumentTermMatrix(corpus,
control = list(
bounds = list(
global =
c(.01, .10)*length(section.1.business)
)
))
# Text to corpus to dtm
corpus <- Corpus(VectorSource(section.1.business))
dtm <- DocumentTermMatrix(corpus,
control = list(
bounds = list(
global =
c(.01, .10)*length(section.1.business)
)
))
mcdonald.cik <- "0000063908"
cocacola.cik <- "0001491675"
pepsi.cik <- "0000077476"
dtm
dtm$v <- rep(1, length(dtm$v))
View(dtm)
CosineSimilarity(A = dtm[raw.data$cik == mcdonald.cik],
B = dtm[raw.data$cik == pepsi.cik])
CosineSimilarity(A = dtm[raw.data$cik == mcdonald.cik,],
B = dtm[raw.data$cik == pepsi.cik,])
CosineSimilarity(A = dtm[raw.data$cik == cocacola.cik,],
B = dtm[raw.data$cik == pepsi.cik,])
CosineSimilarity(A = dtm[raw.data$cik == mcdonald.cik,],
B = dtm[raw.data$cik == cocacola.cik,])
kmeans(x = dtm, centers = 50)
kmeans(x = dtm[[,200]], centers = 50)
kmeans(x = dtm, centers = 50)
kmeans_result <- kmeans(x = dtm, centers = 50)
View(kmeans_result)
cluster_assignments <- kmeans_result$cluster
cluster_centers <- kmeans_result$centers
total_within_ss <- kmeans_result$tot.withinss
total_between_ss <- kmeans_result$totss - kmeans_result$tot.withinss
cluster_sizes <- kmeans_result$size
View(cluster_centers)
View(cluster_centers)
kmeans_result$cluster %>% str()
raw.data$industry.kmeans <- kmeans_result$cluster
raw.data %>%
# define variable
mutate(var = operating.income / total.assets) %>%
# define relevant industries
group_by(industry.kmeans) %>%
# compute average per industry
summarise(varIndustrymeans = mean(var))
# compute standard deviation between each industry
raw.data %>%
# define variable
mutate(var = operating.income / total.assets) %>%
# define relevant industries
group_by(industry.kmeans) %>%
# compute average per industry
summarise(varIndustrymeans = mean(var)) %>%
# compute standard deviation between each industry
pull(varIndustrymeans) %>% sd()
raw.data %>%
# define variable
mutate(var = operating.income / total.assets) %>%
# define relevant industries
group_by(industry.kmeans) %>%
group_by(industry.hoberg.phillips.50) %>%
group_by(industry.fama.french.49) %>%
# compute average per industry
summarise(varIndustrymeans = mean(var)) %>%
# compute standard deviation between each industry
pull(varIndustrymeans) %>% sd()
raw.data %>%
# define variable
mutate(var = operating.income / total.assets) %>%
# define relevant industries
#group_by(industry.kmeans) %>%
#group_by(industry.hoberg.phillips.50) %>%
group_by(industry.fama.french.49) %>%
# compute average per industry
summarise(varIndustrymeans = mean(var)) %>%
# compute standard deviation between each industry
pull(varIndustrymeans) %>% sd()
raw.data %>%
# define variable
mutate(var = operating.income / total.assets) %>%
# define relevant industries
#group_by(industry.kmeans) %>%
group_by(industry.hoberg.phillips.50) %>%
#group_by(industry.fama.french.49) %>%
# compute average per industry
summarise(varIndustrymeans = mean(var)) %>%
# compute standard deviation between each industry
pull(varIndustrymeans) %>% sd()
raw.data %>%
# define variable
mutate(var = operating.income / total.assets) %>%
# define relevant industries
group_by(industry.kmeans) %>%
#group_by(industry.hoberg.phillips.50) %>%
#group_by(industry.fama.french.49) %>%
# compute average per industry
summarise(varIndustrymeans = mean(var)) %>%
# compute standard deviation between each industry
pull(varIndustrymeans) %>% sd()
setwd("/Users/audunhoug/Desktop/BAN400/Lectures/Lecture 7/")
#d
setwd("/Users/audunhoug/Desktop/BAN400/Assignments/Assignment_6/iterations-audunhoug/functions/")
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
install.packages("yaml")
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
library(httr)
install.packages("httr")
install.packages("jsonlite")
install.packages("descTools")
install.packages("DescTools")
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
# Load function for posting GQL-queries and retrieving data:
setwd("/Users/audunhoug/Desktop/BAN400/Assignments/Assignment_6/iterations-audunhoug/")
source("functions/GQL_function.r")
configs <-
read_yaml("vegvesen_configs.yml")
View(configs)
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
setwd("/Users/audunhoug/Desktop/BAN400/Assignments/Assignment_6/iterations-audunhoug/")
source("functions/GQL_function.r")
# The URL we will use is stored below:
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata <-
GQL(
query=gql_metadata_qry,
url = configs$vegvesen_url
)
stations_metadata <-
GQL(
query=gql_metadata_qry,
url = configs$vegvesen_url
)
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
# Load function for posting GQL-queries and retrieving data:
setwd("/Users/audunhoug/Desktop/BAN400/Assignments/Assignment_6/iterations-audunhoug/")
source("functions/GQL_function.r")
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url,(as = "parsed", encoding = "UTF-8")
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url, as = "parsed", encoding = "UTF-8"
)
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
gql_metadata_qry <-'
{
trafficRegistrationPoints {
id
name
latestData {
volumeByDay
}
location {
coordinates {
latLon {
lat
lon
}
}
}
}
}
'
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(gql_metadata_qry
)
stations_metadata <-
GQL(gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata <-
GQL(gql_metadata_qry,
.url = configs$vegvesen_url)
# Load function for posting GQL-queries and retrieving data:
setwd("/Users/audunhoug/Desktop/BAN400/Assignments/Assignment_6/iterations-audunhoug/")
source("functions/GQL_function.r")
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(gql_metadata_qry,
.url = configs$vegvesen_url
)
View(configs)
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
#### 1: Beginning of script
# Load function for posting GQL-queries and retrieving data:
setwd("/Users/audunhoug/Desktop/BAN400/Assignments/Assignment_6/iterations-audunhoug/")
source("functions/GQL_function.r")
# The URL we will use is stored below:
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
# Let's try submitting the query:
stations_metadata <-
GQL(gql_metadata_qry,
.url = configs$vegvesen_url
)
library(jsonlite)
library(httr)
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(gql_metadata_qry,
.url = configs$vegvesen_url
)
source("functions/GQL_function.r")
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(gql_metadata_qry,
.url = configs$vegvesen_url
)
